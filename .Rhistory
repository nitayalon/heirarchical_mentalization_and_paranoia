receiver_dom_level = dom_level[1]
sender_dom_level = dom_level[2]
path_to_experiments_results <- sprintf(path_to_game_results, receiver_dom_level, sender_dom_level)
path_to_dir <- paste(path_to_experiments_results, "simulation_results" ,sep="/")
temp = list.files(path=path_to_dir, pattern="*.csv")
if (length(temp) == 0)
{
next
}
myfiles = lapply(paste(path_to_dir, temp, sep="/"), read.csv)
interim_results <- bind_rows(myfiles)
game_results <- rbind(game_results, cbind(interim_results, receiver_dom_level, sender_dom_level))
}
beliefs <- c()
for(dom_level in dom_levels)
{
receiver_dom_level = dom_level[1]
sender_dom_level = dom_level[2]
for(agent_name in agents_beliefs)
{
path_to_experiments_results <- sprintf(path_to_game_results, receiver_dom_level, sender_dom_level)
path_to_dir <- paste(path_to_experiments_results, "beliefs" ,sep="/")
updated_path = paste(path_to_dir, agent_name, sep="/")
temp = list.files(path=updated_path, pattern="*.csv")
if (length(temp) == 0)
{
next
}
myfiles = lapply(paste(updated_path, temp, sep="/"), read.csv)
interim_results <- bind_rows(myfiles)
beliefs <- rbind(beliefs, cbind(interim_results, receiver_dom_level, sender_dom_level))
}
}
q_values <- c()
for(dom_level in dom_levels)
{
receiver_dom_level = dom_level[1]
sender_dom_level = dom_level[2]
path_to_experiments_results <- sprintf(path_to_game_results, receiver_dom_level, sender_dom_level)
path_to_dir <- paste(path_to_experiments_results, "q_values" ,sep="/")
temp = list.files(path=path_to_dir, pattern="*.csv")
if (length(temp) == 0)
{
next
}
myfiles = lapply(paste(path_to_dir, temp, sep="/"), read.csv)
interim_results <- bind_rows(myfiles)
issue_list <- sapply(myfiles, function(x){class(x$q_value)})
temp[issue_list == "character"][1]
myfiles[issue_list == "character"][1]
q_values <- rbind(q_values, cbind(interim_results, receiver_dom_level, sender_dom_level))
}
custom_colors <- list(
sender_tom = brewer.pal(5, "Reds")[c(2,5)],
receiver_tom = brewer.pal(5, "Blues")[c(3,5)]
)
pl_initial_sender_offer_by_tom <-
game_results %>%
filter(receiver_dom_level  == 0, trial_number == 1) %>%
mutate(sender_threshold = ifelse(sender_threshold > 0, sender_threshold, "random")) %>%
mutate(sender_dom_level = factor(sender_dom_level),
sender_threshold = factor(sender_threshold)) %>%
group_by(sender_threshold, sender_dom_level) %>%
mutate(sender_threshold = factor(sender_threshold, levels = c("random", "0.1", "0.5"))) %>%
ggplot(aes(sender_threshold, offer, fill = sender_dom_level)) +
geom_bar(stat = "summary", position = "dodge") +
ylab("Average offer") +
xlab("Threshold") +
ggtitle('Average first\noffer by sender') +
scale_y_continuous(expand = c(0,0), limits = c(0,0.9)) +
theme(aspect.ratio = 1, legend.position = c(0.90, 0.8)) +
scale_fill_manual(values = custom_colors$sender_tom ,
name = 'Sender\nDoM')
pl_initial_sender_offer_by_tom
threshold_for_recognizing_random <- 0.95
pl_time_to_converge_to_random <-  beliefs %>%
filter(agent_name %in% c("DoM(0)_receiver", "DoM(2)_receiver"),
sender_threshold == 0) %>%
mutate(sender_dom_level = factor(sender_dom_level),
sender_threshold = factor(sender_threshold),
receiver_dom_level = factor(receiver_dom_level),
receiver_threshold = factor(receiver_threshold)) %>%
group_by(agent_name, trial_number, receiver_dom_level)  %>%
summarize(`P(Random)` = mean(`X0.0`))  %>%
mutate(certainty = ifelse(`P(Random)` > threshold_for_recognizing_random, 1, 0)) %>%
filter(certainty == 1) %>%
group_by(agent_name) %>%
summarise(mean_time_for_random = min(trial_number))  %>%
mutate(agent_name = factor(agent_name, levels = c("DoM(2)_receiver", "DoM(0)_receiver"))) %>%
ggplot(aes(agent_name, mean_time_for_random, fill = agent_name)) +
geom_col() +
coord_flip() +
scale_y_continuous(
limits = c(0,7.5),
expand = c(0,0),
breaks = 1:10,
name = "Trial Number") +
scale_x_discrete(name = "Receiver DoM", labels = c(2,0)) +
ggtitle("Trials until receiver\nidentifies random") +
theme(aspect.ratio = 1, legend.position = c(0.80, 0.8)) +
scale_fill_manual(values = rev(custom_colors$receiver_tom),
name = "Receiver\nDoM", labels = c(2,0))
pl_time_to_converge_to_random
beliefs %>%
filter(agent_name %in% c("DoM(0)_receiver", "DoM(2)_receiver"),
sender_threshold == 0)
beliefs %>%
filter(agent_name %in% c("DoM(0)_receiver", "DoM(2)_receiver"),
sender_threshold == 0) %>%
mutate(sender_dom_level = factor(sender_dom_level),
sender_threshold = factor(sender_threshold),
receiver_dom_level = factor(receiver_dom_level),
receiver_threshold = factor(receiver_threshold)) %>%
group_by(agent_name, trial_number, receiver_dom_level)  %>%
summarize(`P(Random)` = mean(`X0.0`))  %>%
mutate(certainty = ifelse(`P(Random)` > threshold_for_recognizing_random, 1, 0)) %>%
filter(certainty == 1) %>%
group_by(agent_name) %>%
summarise(mean_time_for_random = min(trial_number))
beliefs %>%
filter(agent_name %in% c("DoM(0)_receiver", "DoM(2)_receiver"),
sender_threshold == 0) %>%
mutate(sender_dom_level = factor(sender_dom_level),
sender_threshold = factor(sender_threshold),
receiver_dom_level = factor(receiver_dom_level),
receiver_threshold = factor(receiver_threshold)) %>%
group_by(agent_name, trial_number, receiver_dom_level)  %>%
summarize(`P(Random)` = mean(`X0.0`))
pl_total_reward_across_game_paranoia <- game_results %>%
filter(sender_dom_level == "-1",
sender_threshold > 0) %>%
mutate(sender_dom_level = factor(sender_dom_level),
sender_threshold = factor(sender_threshold),
receiver_dom_level = factor(receiver_dom_level),
receiver_threshold = factor(receiver_threshold)) %>%
mutate(dyad = fct_cross(sender_dom_level, receiver_dom_level)) %>%
group_by(trial_number, sender_dom_level, receiver_dom_level,  receiver_threshold, sender_threshold) %>%
summarise(average_receiver_reward = mean(receiver_reward),
average_sender_reward = mean(sender_reward)) %>%
arrange(sender_dom_level, receiver_dom_level, sender_threshold,
receiver_threshold) %>%
group_by(receiver_threshold, sender_threshold, sender_dom_level, receiver_dom_level) %>%
mutate(cumulative_receiver_reward = cumsum(average_receiver_reward),
cumulative_sender_reward = cumsum(average_sender_reward))  %>%
group_by(receiver_dom_level) %>%
summarize(total_game_reward = sum(cumulative_receiver_reward)) %>%
ggplot(aes(receiver_dom_level, total_game_reward, fill = receiver_dom_level)) +
geom_col() +
scale_y_continuous(
expand = c(0,0),
name = "Sum of Game Reward",
limits = c(0,14),
breaks = seq(0,12,2)
) +
ggtitle("Reward by paranoid and\nnon-paranoid ToM agent") +
scale_x_discrete(
name = "Receiver DoM level"
) +
theme(aspect.ratio = 1) +
scale_fill_manual(values = custom_colors$receiver_tom) +
guides(fill = "none")
pl_total_reward_across_game_paranoia
sid = 210
sender_dom_level_for_plot = 1
receiver_dom_level_for_plot = 0
custom_colors$sender_type <- rev(brewer.pal(n =7, name = "RdPu"))[c(1,4,5)]
custom_colors$accept_reject <- c("white", "white")
custom_shape <- list(
accept = 22,
reject = 21
)
dynamics_plot_aspect_ratio <- .8
accept_rejct_point_size <- 2.5
pl_domminus1_offers <- game_results %>%
filter(receiver_dom_level == 0,
sender_dom_level == -1,
seed == sid) %>%
mutate(sender_threshold = factor(sender_threshold),
response = factor(response, labels = c('reject','accept'))) %>%
mutate(sender_threshold = factor(sender_threshold)) %>%
ggplot(aes(x = trial_number, y = offer)) +
geom_line(aes(colour = sender_threshold), size = 1.5) +
geom_point(aes(fill = response ,shape = factor(response)), size = accept_rejct_point_size) +
scale_fill_manual(values = custom_colors$accept_reject,
name = "Receiver response") +
scale_color_manual(
values = custom_colors$sender_type,
name = expression(paste('Sender threshold')),
labels = c("random", "\u03B7 = 0.1" ,"\u03B7 = 0.5")
)+
# scale_shape_manual(values=c(4, 15)) +
scale_shape_manual(values=c(custom_shape$reject, custom_shape$accept),
name = "Receiver response") +
scale_x_continuous(name="Trial", breaks=seq(0, 10, 1)) +
scale_y_continuous(limits = c(0,1),breaks = c(0,.5,1)) +
labs(y = 'Offer', x= 'Trial', shape = "Receiver's response") +
ggtitle('Sender Offers: DoM(-1)') +
theme(aspect.ratio = dynamics_plot_aspect_ratio) +
guides(color = "none", shape = "none", fill = "none")
pl_dom1_offers <- game_results %>%
filter(receiver_dom_level == 0,
sender_dom_level == 1,
seed == sid) %>%
mutate(sender_threshold = factor(sender_threshold),
response = factor(response, labels = c('reject','accept'))) %>%
mutate(sender_threshold = factor(sender_threshold)) %>%
ggplot(aes(x = trial_number, y = offer)) +
geom_line(
aes(
colour = sender_threshold,
linetype = sender_threshold,
alpha = sender_threshold),
size = 1.5) +
geom_point(aes(fill = response ,shape = factor(response)), size = accept_rejct_point_size) +
scale_fill_manual(values = custom_colors$accept_reject,
name = "Receiver response") +
scale_color_manual(
values = custom_colors$sender_type,
name = expression(paste('Sender threshold')),
labels = c("random", "\u03B7 = 0.1" ,"\u03B7 = 0.5")
) +
# scale_shape_manual(values=c(4, 15)) +
scale_shape_manual(values=c(custom_shape$reject, custom_shape$accept),
name = "Receiver response") +
scale_linetype_manual(values = c("longdash", "solid", "solid")) +
scale_alpha_manual(values = c(0.3, 1, 1)) +
scale_x_continuous(name="Trial", breaks=seq(0, 10, 1)) +
scale_y_continuous(limits = c(0,1),breaks = c(0,.5,1)) +
labs(y = '', x= 'Trial') +
guides(linetype = "none", alpha = "none") +
ggtitle('Sender Offers: DoM(1)') +
theme(aspect.ratio = dynamics_plot_aspect_ratio)
pl_domminus1_offers + pl_dom1_offers +
plot_layout(guides = "collect")
pl_beliefs_dom0_domminus1 <- beliefs %>%
filter(receiver_dom_level == 0,
sender_dom_level == -1,
seed == sid) %>%
mutate(
`P(0.0)` = `X0.0`,
`P(0.1)` = `X0.1`,
`P(0.5)` = `X0.5`
) %>%
ggplot() +
geom_line(aes(x = trial_number, y = `P(0.0)`, colour='`P(0.0)`'), size=1.0) +
geom_line(aes(x = trial_number, y = `P(0.1)`, colour='`P(0.1)`'), size=1.0) +
geom_line(aes(x = trial_number, y = `P(0.5)`, colour='`P(0.5)`'), size=1.0) +
scale_linetype_manual(values=c("solid", "dotted", "solid"))+
scale_color_manual(
values = custom_colors$sender_type,
name = expression(paste('Sender threshold')),
labels = c("random", "\u03B7 = 0.5" ,"\u03B7 = 0.1")) +
facet_grid(.~sender_threshold) +
scale_x_continuous(name = 'Trial', breaks = c(0,5,10) ) +
scale_y_continuous(name = "Posterior P.", breaks = c(0,1)) +
ggtitle('Receiver beliefs:\nDoM(0) vs. DoM(-1)') +
theme(aspect.ratio = 1) +
guides(color = "none")
pl_beliefs_dom0_domminus1 <- beliefs %>%
filter(receiver_dom_level == 0,
sender_dom_level == -1,
seed == sid) %>%
mutate(
`P(0.0)` = `X0.0`,
`P(0.1)` = `X0.1`
) %>%
ggplot() +
geom_line(aes(x = trial_number, y = `P(0.0)`, colour='`P(0.0)`'), size=1.0) +
geom_line(aes(x = trial_number, y = `P(0.1)`, colour='`P(0.1)`'), size=1.0) +
scale_linetype_manual(values=c("solid", "dotted", "solid"))+
scale_color_manual(
values = custom_colors$sender_type,
name = expression(paste('Sender threshold')),
labels = c("random", "\u03B7 = 0.5" ,"\u03B7 = 0.1")) +
facet_grid(.~sender_threshold) +
scale_x_continuous(name = 'Trial', breaks = c(0,5,10) ) +
scale_y_continuous(name = "Posterior P.", breaks = c(0,1)) +
ggtitle('Receiver beliefs:\nDoM(0) vs. DoM(-1)') +
theme(aspect.ratio = 1) +
guides(color = "none")
pl_beliefs_dom0_dom1 <-
beliefs %>%
filter(receiver_dom_level == 0,
sender_dom_level == 1,
seed == sid) %>%
mutate(
`P(0.0)` = `X0.0`,
`P(0.1)` = `X0.1`
)  %>%
ggplot() +
geom_line(aes(x = trial_number, y = `P(0.0)`, colour='`P(0.0)`'), size=1.0) +
geom_line(aes(x = trial_number, y = `P(0.1)`, colour='`P(0.1)`'), size=1.0) +
scale_linetype_manual(values=c("solid", "dotted", "solid"))+
scale_color_manual(
values = custom_colors$sender_type,
name = expression(paste('Sender threshold')),
labels = c("random", "\u03B7 = 0.5" ,"\u03B7 = 0.1")) +
facet_grid(.~sender_threshold)  +
scale_x_continuous(name = 'Trial', breaks = c(0,5,10) ) +
scale_y_continuous(name = "", breaks = c(0,1)) +
ggtitle('Receiver beliefs:\nDoM(0) vs. DoM(1)') +
theme(aspect.ratio = 1) +
guides(color = "none")
pl_beliefs_dom0_domminus1 + pl_beliefs_dom0_dom1 + plot_layout(guides = "collect")
actions <- seq(0,1,0.05)
actions
low = 0.0
high = 1.0
actions > low & actions <= high
(actions > low & actions <= high) * 0.95
(actions <= low & actions > high) * -0.95
(actions <= low || actions > high) * -0.95
(actions <= low | actions > high) * -0.95
low = 0.3
(actions <= low | actions > high) * -0.95
eta = 0.1
policy <- function(eta, low, high)
{
updated_qv <- q_values(eta) + weigths(low, high)
policy <- exp(updated_qv/0.1) / sum(exp(updated_qv/0.1))
return(policy)
}
weigths <- function(low, high)
{
w = (actions <= low | actions > high) * -0.95
}
q_values <- function(eta)
{
return(actions - eta)
}
policy(eta, low, high)
q_values <- function(eta)
{
return(1 - actions - eta)
}
policy(eta, low, high)
policy <- function(eta, low, high)
{
updated_qv <- q_values(eta) + weigths(low, high)
policy <- exp(updated_qv/0.1) / sum(exp(updated_qv/0.1))
return(sum(policy * actions))
}
policy(eta, low, high)
policy(eta, 0.4, high)
policy(eta, 0.5, high)
policy(eta, 0.5, 0.6)
2**10
(pl_domminus1_offers / pl_beliefs_dom0_domminus1 + plot_layout(heights = c(5,2))) |
(pl_dom1_offers / pl_beliefs_dom0_dom1+ plot_layout(heights = c(5,2))) +
plot_layout(guides = "collect") + plot_annotation(tag_levels = "A")
policy(eta, 0.5, 0.6)
actions <- c(T,F)
recursive_span <- function(action, observation, previous_low, previous_high,depth)
{
reward = observation * action
if(depth >= 10)
{
return(reward)
}
new_low = observation * (1-action) + previous_low*action
new_high = observation * (action) + previous_high*(1-action)
new_observation = policy(0.1, new_low, new_high)
future_values = sapply(actions, function(x){recursive_span(x,new_observation,new_low,new_high)})
return(reward + max(future_values))
}
recursive_span <- function(action, observation, previous_low, previous_high,depth)
{
reward = observation * action
if(depth >= 10)
{
return(reward)
}
new_low = observation * (1-action) + previous_low*action
new_high = observation * (action) + previous_high*(1-action)
new_observation = policy(0.1, new_low, new_high)
future_values = sapply(actions, function(x){recursive_span(x,new_observation,new_low,new_high,
depth + 1)})
return(reward + max(future_values))
}
recursive_span(T, 0.2, 0.0, 1.0, 0)
debugSource("C:/Users/Gili/Documents/Max_Planck/Hierarchical-modelling/simulations/simple_tom_zero_plnannig.R", echo=TRUE)
depth
recursive_span(T, 0.2, 0.0, 1.0, 0)
source("~/Max_Planck/Hierarchical-modelling/simulations/simple_tom_zero_plnannig.R", echo=TRUE)
recursive_span <- function(action, observation, previous_low, previous_high,depth)
{
reward = observation * action
if(depth >= 10)
{
return(reward)
}
new_low = observation * (1-action) + previous_low*action
new_high = observation * (action) + previous_high*(1-action)
new_observation = policy(0.1, new_low, new_high)
future_values = sapply(actions, function(x){recursive_span(x,new_observation,new_low,new_high,
depth + 1)})
return(reward + 0.99 * max(future_values))
}
recursive_span(T, 0.2, 0.0, 1.0, 0)
recursive_span(F, 0.2, 0.0, 1.0, 0)
recursive_span <- function(action, observation, previous_low, previous_high,depth)
{
reward = observation * action
if(depth >= 2)
{
return(reward)
}
new_low = observation * (1-action) + previous_low*action
new_high = observation * (action) + previous_high*(1-action)
new_observation = policy(0.1, new_low, new_high)
future_values = sapply(actions, function(x){recursive_span(x,new_observation,new_low,new_high,
depth + 1)})
return(reward + 0.99 * max(future_values))
}
recursive_span(T, 0.2, 0.0, 1.0, 0)
recursive_span(F, 0.2, 0.0, 1.0, 0)
recursive_span <- function(action, observation, previous_low, previous_high,depth)
{
reward = observation * action
if(depth >= 1)
{
return(reward)
}
new_low = observation * (1-action) + previous_low*action
new_high = observation * (action) + previous_high*(1-action)
new_observation = policy(0.1, new_low, new_high)
future_values = sapply(actions, function(x){recursive_span(x,new_observation,new_low,new_high,
depth + 1)})
return(reward + 0.99 * max(future_values))
}
recursive_span(T, 0.2, 0.0, 1.0, 0)
recursive_span(F, 0.2, 0.0, 1.0, 0)
policy(0.1, 0.0, 0.2)
policy(0.1, 0.2, 1.0)
recursive_span(T, 0.15, 0.0, 1.0, 10)
recursive_span <- function(action, observation, previous_low, previous_high,depth)
{
reward = observation * action
if(depth >= 10)
{
return(reward)
}
new_low = observation * (1-action) + previous_low*action
new_high = observation * (action) + previous_high*(1-action)
new_observation = policy(0.1, new_low, new_high)
future_values = sapply(actions, function(x){recursive_span(x,new_observation,new_low,new_high,
depth + 1)})
return(reward + max(future_values))
}
recursive_span(T, 0.15, 0.0, 1.0, 10)
recursive_span(T, 0.15, 0.0, 1.0, 0)
recursive_span(F, 0.15, 0.0, 1.0, 0)
2/10
0.6*5
1 - observations - eta
debugSource("C:/Users/Gili/Documents/Max_Planck/Hierarchical-modelling/simulations/simple_tom_zero_plnannig.R", echo=TRUE)
weigths(low, high)
weigths(low, high)
q_values(eta)
weigths(low, high)
weigths <- function(low, high)
{
return(w = (observations <= low | observations > high) * -0.95)
}
weigths(low, high)
!(observations > low & observations <= high)
high
low
!(observations > low & observations <= high) * -0.95
!(observations > low & observations <= high)
!(observations > low & observations <= high) * -0.95
w = !(observations > low & observations <= high) * -0.95
w = !(observations > low & observations <= high)
w * 0.95
w * -0.95
weigths <- function(low, high)
{
w = !(observations > low & observations <= high)
return(w * -0.95)
}
updated_qv <- q_values(eta) + weigths(low, high)
updated_qv
policy <- exp(updated_qv/0.1) / sum(exp(updated_qv/0.1))
sum(policy * observations)
source("~/Max_Planck/Hierarchical-modelling/simulations/simple_tom_zero_plnannig.R", echo=TRUE)
(pl_dom1_offers_dom2 / pl_beliefs_dom1_dom2 + plot_layout(heights = c(5,2))) |
(pl_domminus1_offers_dom2 / pl_beliefs_domminus1_dom2+ plot_layout(heights = c(5,2))) +
plot_layout(guides = "collect") + plot_annotation(tag_levels = "A")
pl_beliefs_dom1_dom2 <-
beliefs %>%
filter(receiver_dom_level == 2 & sender_dom_level == 1 | receiver_dom_level == 2 & sender_dom_level == -1 & sender_threshold == 0,
seed == sid) %>%
mutate(
`P(0.0)` = `X0.0`,
`P(0.1)` = `X0.1`,
`P(0.5)` = `X0.5`
)  %>%
ggplot() +
geom_line(aes(x = trial_number, y = `P(0.0)`, colour='`P(0.0)`'), size=1.0) +
geom_line(aes(x = trial_number, y = `P(0.1)`, colour='`P(0.1)`'), size=1.0) +
geom_line(aes(x = trial_number, y = `P(0.5)`, colour='`P(0.5)`'), size=1.0) +
scale_linetype_manual(values=c("solid", "dotted", "solid"))+
scale_color_manual(
values = custom_colors$sender_type,
name = expression(paste('Sender threshold')),
labels = c("random", "\u03B7 = 0.5" ,"\u03B7 = 0.1")) +
facet_grid(.~sender_threshold)  +
scale_x_continuous(name = 'Trial', breaks = c(0,5,10) ) +
scale_y_continuous(name = "", breaks = c(0,1)) +
ggtitle('Receiver beliefs:\nDoM(2) vs. DoM(1)') +
theme(aspect.ratio = 1) +
guides(color = "none")
